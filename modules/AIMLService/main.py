# CityResQ360-DTUDZ - Smart City Emergency Response System
# Copyright (C) 2025 DTU-DZ Team
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

from fastapi import FastAPI, File, UploadFile, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
import google.generativeai as genai
from PIL import Image
import io
import base64
import logging
import time
import json
from typing import Dict, List, Optional
from datetime import datetime

# Import authentication middleware
from middleware.auth import authenticate, optional_authenticate

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="CityResQ360 AI/ML Service",
    version="1.0.0",
    description="AI-powered incident detection for smart city emergency response"
)

# CORS middleware - allow all origins for development
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for open API
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure Gemini API - use environment variable for security
import os
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")
if not GEMINI_API_KEY:
    logger.warning("‚ö†Ô∏è GEMINI_API_KEY environment variable not set! AI analysis will fail.")
else:
    genai.configure(api_key=GEMINI_API_KEY)

# Global Gemini model
gemini_model = None

# Enhanced Vietnamese labels mapping
INCIDENT_LABELS = {
    "pothole": {
        "vi": "·ªî g√†",
        "en": "Pothole",
        "severity": "medium",
        "priority": "high",
        "category_id": 1,  # Map to CoreAPI categories
        "keywords": ["road", "damage", "hole", "asphalt", "street", "pavement", "crack", "broken"],
        "negative_keywords": ["car", "truck", "person", "vehicle"],
    },
    "flooding": {
        "vi": "Ng·∫≠p l·ª•t",
        "en": "Flooding",
        "severity": "high",
        "priority": "critical",
        "category_id": 2,
        "keywords": ["water", "flood", "rain", "street", "submerged", "puddle", "wet"],
        "negative_keywords": [],
    },
    "traffic_light": {
        "vi": "ƒê√®n giao th√¥ng",
        "en": "Traffic Light",
        "severity": "medium",
        "priority": "high",
        "category_id": 3,
        "keywords": ["traffic", "light", "signal", "broken", "intersection", "crossing"],
        "negative_keywords": [],
    },
    "waste": {
        "vi": "R√°c th·∫£i",
        "en": "Waste",
        "severity": "low",
        "priority": "medium",
        "category_id": 4,
        "keywords": ["garbage", "trash", "waste", "litter", "rubbish", "debris", "dump"],
        "negative_keywords": ["car", "person", "vehicle"],
    },
    "traffic_jam": {
        "vi": "K·∫πt xe",
        "en": "Traffic Jam",
        "severity": "medium",
        "priority": "medium",
        "category_id": 5,
        "keywords": ["traffic", "jam", "congestion", "cars", "queue", "stuck"],
        "negative_keywords": [],
    },
    "other": {
        "vi": "S·ª± c·ªë kh√°c",
        "en": "Other",
        "severity": "medium",
        "priority": "medium",
        "category_id": 6,
        "keywords": [],
        "negative_keywords": [],
    }
}


@app.on_event("startup")
async def load_models():
    """Initialize Gemini Vision API"""
    global gemini_model
    
    try:
        logger.info("üöÄ Initializing Gemini Vision API...")
        
        # Use Gemini 3 Pro Image Preview - Latest and most capable
        gemini_model = genai.GenerativeModel('gemini-3-pro-image-preview')
        
        logger.info("‚úÖ Gemini 3 Pro Image Preview initialized successfully")
        logger.info("üåü Using Google's NEWEST and most advanced vision model")
        logger.info("üí∞ Cost-effective with generous free tier")
        
    except Exception as e:
        logger.error(f"‚ùå Error loading Gemini: {str(e)}")
        raise



def analyze_image_content(image: Image.Image) -> Dict:
    """Analyze image using Gemini Vision API"""
    try:
        # Ensure RGB mode
        if image.mode != "RGB":
            logger.info(f"Converting image from {image.mode} to RGB")
            image = image.convert("RGB")
        
        # Resize if too large (Gemini accepts up to 4MB)
        max_size = 1024
        if max(image.size) > max_size:
            logger.info(f"Resizing image from {image.size}")
            image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
            logger.info(f"Resized to {image.size}")
        
        logger.info(f"üì∏ Analyzing with Gemini Vision: size={image.size}, mode={image.mode}")
        
        # Vietnamese prompt for incident classification
        prompt = """Ph√¢n t√≠ch ·∫£nh n√†y v√† x√°c ƒë·ªãnh lo·∫°i s·ª± c·ªë ƒë√¥ th·ªã (urban incident). 

Ch·ªçn M·ªòT trong c√°c lo·∫°i sau:
1. **pothole** (·ªï g√†) - ƒë∆∞·ªùng h·ªèng, ·ªï g√†, v·∫øt n·ª©t ƒë∆∞·ªùng
2. **flooding** (ng·∫≠p l·ª•t) - n∆∞·ªõc ng·∫≠p, l≈© l·ª•t, ƒë∆∞·ªùng ng·∫≠p n∆∞·ªõc
3. **traffic_light** (ƒë√®n giao th√¥ng h·ªèng) - ƒë√®n t√≠n hi·ªáu h·ªèng, ƒë√®n giao th√¥ng kh√¥ng ho·∫°t ƒë·ªông
4. **waste** (r√°c th·∫£i) - r√°c b·∫©n, r√°c th·∫£i tr√†n lan, b√£i r√°c
5. **traffic_jam** (k·∫πt xe) - t·∫Øc ƒë∆∞·ªùng, nhi·ªÅu xe, giao th√¥ng √πn t·∫Øc
6. **other** (kh√°c) - c√°c s·ª± c·ªë kh√°c ho·∫∑c kh√¥ng x√°c ƒë·ªãnh r√µ

Tr·∫£ v·ªÅ ƒê√öNG ƒë·ªãnh d·∫°ng JSON sau (kh√¥ng th√™m markdown, ch·ªâ pure JSON):
{
  "label": "t√™n_lo·∫°i_s·ª±_c·ªë",
  "confidence": 0.85,
  "description": "M√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ s·ª± c·ªë (ti·∫øng Vi·ªát)",
  "detected_objects": ["danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng nh√¨n th·∫•y"]
}

CH√ö √ù: 
- confidence t·ª´ 0.0 ƒë·∫øn 1.0
- N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, d√πng "other" v√† confidence th·∫•p h∆°n
- description ph·∫£i b·∫±ng ti·∫øng Vi·ªát"""

        # Call Gemini API
        response = gemini_model.generate_content([prompt, image])
        
        # Parse response
        response_text = response.text.strip()
        
        # Remove markdown code blocks if present
        if response_text.startswith("```"):
            response_text = response_text.split("```")[1]
            if response_text.startswith("json"):
                response_text = response_text[4:]
            response_text = response_text.strip()
        
        logger.info(f"üìù Gemini response: {response_text[:200]}...")
        
        # Parse JSON
        try:
            gemini_result = json.loads(response_text)
        except json.JSONDecodeError:
            logger.warning("Failed to parse Gemini JSON, using fallback")
            gemini_result = {
                "label": "other",
                "confidence": 0.60,
                "description": "Kh√¥ng th·ªÉ ph√¢n t√≠ch ch√≠nh x√°c",
                "detected_objects": []
            }
        
        # Map to our format
        label = gemini_result.get("label", "other")
        confidence = float(gemini_result.get("confidence", 0.70))
        description = gemini_result.get("description", "")
        detected_objects = gemini_result.get("detected_objects", [])
        
        # Get incident info
        info = INCIDENT_LABELS.get(label, INCIDENT_LABELS["other"])
        
        result = {
            "label": label,
            "label_vi": info["vi"],
            "label_en": info["en"],
            "confidence": confidence,
            "severity": info["severity"],
            "priority": info["priority"],
            "category_id": info["category_id"],
            "description": description or f'{info["vi"]} ƒë∆∞·ª£c ph√°t hi·ªán v·ªõi ƒë·ªô tin c·∫≠y {int(confidence*100)}%',
            "detected_objects": detected_objects,
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "ai_engine": "gemini-3-pro-image-preview"
        }
        
        logger.info(f"‚úÖ Gemini analysis: {label} (confidence: {confidence:.2f})")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Gemini analysis error: {str(e)}")
        logger.error(f"Traceback: ", exc_info=True)
        
        # Fallback
        return {
            "label": "other",
            "label_vi": "S·ª± c·ªë kh√°c",
            "label_en": "Other",
            "confidence": 0.50,
            "severity": "medium",
            "priority": "medium",
            "category_id": 6,
            "description": "L·ªói khi ph√¢n t√≠ch AI",
            "detected_objects": [],
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "ai_engine": "fallback"
        }



def classify_incident(classification_results: List, detection_results: List) -> Dict:
    """Advanced AI classification for all incident types"""
    
    # Extract predictions
    top_classification = classification_results[0] if classification_results else {}
    detected_objects = [obj["label"].lower() for obj in detection_results[:15]]
    
    logger.info(f"Classification: {top_classification}")
    logger.info(f"Objects: {detected_objects}")
    
    # Analyze detected objects
    analysis = {
        "vehicles": [],
        "infrastructure": [],
        "water_related": [],
        "waste_related": [],
        "damage_indicators": [],
        "people": []
    }
    
    # Categorize detected objects
    for obj in detected_objects:
        if any(v in obj for v in ["car", "truck", "bus", "motorcycle", "bike", "vehicle"]):
            analysis["vehicles"].append(obj)
        elif any(i in obj for i in ["traffic light", "stop sign", "street sign", "road"]):
            analysis["infrastructure"].append(obj)
        elif any(w in obj for w in ["water", "puddle", "rain"]):
            analysis["water_related"].append(obj)
        elif any(g in obj for g in ["bottle", "bag", "trash", "garbage"]):
            analysis["waste_related"].append(obj)
        elif any(d in obj for d in ["hole", "crack", "damage", "broken"]):
            analysis["damage_indicators"].append(obj)
        elif "person" in obj:
            analysis["people"].append(obj)
    
    vehicle_count = len(analysis["vehicles"])
    people_count = len(analysis["people"])
    
    # Score each incident type
    incident_scores = {}
    
    for incident_type, info in INCIDENT_LABELS.items():
        score = 0.0
        confidence_reasons = []
        
        if incident_type == "traffic_jam":
            if vehicle_count >= 5:
                score += 0.9
                confidence_reasons.append(f"Nhi·ªÅu ph∆∞∆°ng ti·ªán ({vehicle_count})")
            elif vehicle_count >= 2:
                score += 0.6
                confidence_reasons.append(f"C√≥ ph∆∞∆°ng ti·ªán ({vehicle_count})")
            
            if people_count > 0:
                score += 0.3
                confidence_reasons.append(f"C√≥ ng∆∞·ªùi ({people_count})")
        
        elif incident_type == "pothole":
            road_present = any("road" in obj or "street" in obj for obj in detected_objects)
            damage_present = len(analysis["damage_indicators"]) > 0
            
            if damage_present and road_present:
                score += 0.8
                confidence_reasons.append("C√≥ h∆∞ h·∫°i tr√™n ƒë∆∞·ªùng")
            elif road_present and vehicle_count < 3:
                score += 0.5
                confidence_reasons.append("C√≥ ƒë∆∞·ªùng, √≠t ph∆∞∆°ng ti·ªán")
            
            if vehicle_count >= 4:
                score *= 0.1
        
        elif incident_type == "flooding":
            water_present = len(analysis["water_related"]) > 0
            
            if water_present:
                score += 0.9
                confidence_reasons.append("Ph√°t hi·ªán n∆∞·ªõc")
        
        elif incident_type == "waste":
            waste_present = len(analysis["waste_related"]) > 0
            
            if waste_present:
                score += 0.8
                confidence_reasons.append("Ph√°t hi·ªán r√°c th·∫£i")
            
            if vehicle_count >= 3:
                score *= 0.3
        
        elif incident_type == "traffic_light":
            light_present = any("traffic light" in obj or "stop sign" in obj 
                              for obj in analysis["infrastructure"])
            
            if light_present:
                score += 0.9
                confidence_reasons.append("Ph√°t hi·ªán ƒë√®n giao th√¥ng")
        
        elif incident_type == "other":
            if all(s < 0.4 for s in incident_scores.values()):
                score += 0.5
                confidence_reasons.append("Kh√¥ng x√°c ƒë·ªãnh r√µ lo·∫°i s·ª± c·ªë")
        
        # Record score if significant
        if score > 0.1:
            incident_scores[incident_type] = score
            logger.info(f"{incident_type}: {score:.2f} - {confidence_reasons}")
    
    # Select best match
    if incident_scores:
        sorted_scores = sorted(incident_scores.items(), key=lambda x: x[1], reverse=True)
        best_match = sorted_scores[0]
        incident_type = best_match[0]
        raw_score = best_match[1]
        
        # Normalize confidence (0.55 - 0.95)
        confidence = min(0.55 + (raw_score * 0.4), 0.95)
    else:
        # Fallback
        if vehicle_count >= 3:
            incident_type = "traffic_jam"
            confidence = 0.70
        elif any("water" in obj for obj in detected_objects):
            incident_type = "flooding"
            confidence = 0.65
        else:
            incident_type = "other"
            confidence = 0.60
    
    info = INCIDENT_LABELS[incident_type]
    
    return {
        "label": incident_type,
        "label_vi": info["vi"],
        "label_en": info["en"],
        "confidence": round(confidence, 2),
        "severity": info["severity"],
        "priority": info["priority"],
        "category_id": info["category_id"],
        "description": f"{info['vi']} ƒë∆∞·ª£c ph√°t hi·ªán v·ªõi ƒë·ªô tin c·∫≠y {round(confidence * 100)}%",
        "detected_objects": detected_objects[:10],
        "analysis": analysis,
        "timestamp": datetime.utcnow().isoformat() + "Z"
    }


@app.post("/analyze")
async def analyze_image(
    file: UploadFile = File(...),
    user: Optional[Dict] = Depends(optional_authenticate)
):
    """
    Analyze uploaded image - Public API with optional authentication
    
    - **No auth**: Limited to basic analysis
    - **With auth**: Full analysis + user tracking
    """
    
    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File must be an image")
    
    try:
        # Read and process image
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        # Convert to RGB if needed
        if image.mode != "RGB":
            image = image.convert("RGB")
        
        # Analyze image
        analysis = analyze_image_content(image)
        
        # Add user info if authenticated
        if user:
            analysis['analyzed_by'] = {
                'user_id': user.get('user_id'),
                'auth_type': user.get('auth_type')
            }
            logger.info(f"Analysis by user {user.get('user_id')} ({user.get('auth_type')}): {analysis['label']} ({analysis['confidence']})")
        else:
            logger.info(f"Public analysis: {analysis['label']} ({analysis['confidence']})")
        
        return {
            "success": True,
            "analysis": analysis
        }
        
    except Exception as e:
        logger.error(f"Error processing image: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/analyze-base64")
async def analyze_base64_image(
    data: dict,
    user: Optional[Dict] = Depends(optional_authenticate)
):
    """
    Analyze base64 encoded image - For mobile apps
    
    - **No auth**: Limited to basic analysis
    - **With auth**: Full analysis + user tracking
    """
    
    if "image_base64" not in data:
        raise HTTPException(status_code=400, detail="image_base64 field required")
    
    try:
        # Decode base64 image
        image_data = base64.b64decode(data["image_base64"])
        image = Image.open(io.BytesIO(image_data))
        
        # Convert to RGB if needed
        if image.mode != "RGB":
            image = image.convert("RGB")
        
        # Analyze image
        analysis = analyze_image_content(image)
        
        # Add user info if authenticated
        if user:
            analysis['analyzed_by'] = {
                'user_id': user.get('user_id'),
                'auth_type': user.get('auth_type')
            }
        
        return {
            "success": True,
            "analysis": analysis
        }
        
    except Exception as e:
        logger.error(f"Error processing base64 image: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/analyze-for-report")
async def analyze_for_report(
    file: UploadFile = File(...),
    user: Optional[Dict] = Depends(optional_authenticate)  # Made optional - called from CoreAPI (already authenticated)
):
    """
    Analyze image and return CoreAPI Report format - **Requires authentication**
    
    For internal integration with CoreAPI /media/upload flow
    """
    
    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File must be an image")
    
    try:
        # Read and process image
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        # Convert to RGB if needed
        if image.mode != "RGB":
            image = image.convert("RGB")
        
        # Analyze image
        analysis = analyze_image_content(image)
        
        # Format response for CoreAPI Report creation
        report_data = {
            "success": True,
            "data": {
                "danh_muc_id": analysis["category_id"],
                "tieu_de": f"Ph√°t hi·ªán {analysis['label_vi']}",
                "mo_ta": analysis["description"],
                "muc_do_uu_tien": analysis["priority"],
                "muc_do_nghiem_trong": analysis["severity"],
                "ai_analysis": {
                    "label": analysis["label"],
                    "label_vi": analysis["label_vi"],
                    "confidence": analysis["confidence"],
                    "detected_objects": analysis["detected_objects"],
                    "timestamp": analysis["timestamp"]
                },
                "analyzed_by": {
                    "user_id": user.get('user_id'),
                    "auth_type": user.get('auth_type')
                }
            }
        }
        
        logger.info(f"Report analysis by user {user.get('user_id')}: {analysis['label']} ({analysis['confidence']})")
        
        return report_data
        
    except Exception as e:
        logger.error(f"Error processing image for report: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "service": "AIMLService",
        "status": "healthy",
        "models_loaded": image_classifier is not None and object_detector is not None,
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "timestamp": datetime.utcnow().isoformat() + "Z"
    }


@app.get("/")
async def root():
    return {
        "service": "CityResQ360 AI/ML Service",
        "version": "1.0.0",
        "endpoints": {
            "/analyze": "POST - Upload image file for analysis",
            "/analyze-base64": "POST - Analyze base64 encoded image",
            "/analyze-for-report": "POST - Analyze and return CoreAPI Report format",
            "/health": "GET - Service health check"
        }
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8003)
